from typing import List
import pyparsing as pp

class TokenTypeParseAction(object):
    """
    Parser designed to parser string like: 

    <'CONST'>
    <WS>
    <EOF>
    <'INTEGER'>
    """

    def __init__(self,tokens) -> None:
        print(f">>>> Parsing type tokens={tokens}")
        if len(tokens[0]) > 3:
            # the optional "'" were present
            self.value = tokens[0][2].replace("'","")
        else:
            self.value = tokens[0][1]

    def generate(self):
        return self.value


class TokenValueParseAction(object):
    """
    Parser designed to parser string like: 

    0:4='Const',<'CONST'>
    5:5=' ',<WS>
    936:935='<EOF>',<EOF>
    24:30='Integer',<'INTEGER'>
    """

    def __init__(self,tokens) -> None:
        print(f">>> tokens={tokens}")
        print("DETECTED content -> ", tokens[0][1])
        print("DETECTED type -> ", tokens[0][1])
        self.start_byte = tokens[0][0]
        self.end_byte = tokens[0][2]
        self.content = tokens[0][5]
        self.type = tokens[0][8]

    def generate(self):
        "".join(( self.start_byte, self.end_byte, self.content, self.type.generate()))

# Common Pitfalls When Writing Parsers
# https://github.com/pyparsing/pyparsing/wiki/Common-Pitfalls-When-Writing-Parsers
# Gentle intro to pyparsing
# https://dev.to/zchtodd/building-parsers-for-fun-and-profit-with-pyparsing-4l9e
# == token type parser ==
type_identifier = pp.Word( pp.alphanums + "_", exclude_chars="'").set_name("type_identifier")
token_type_cls_word = pp.Group("<"+ pp.Optional(pp.Char("'")) + type_identifier + pp.Optional(pp.Char("'")) + ">")
token_type_parser = token_type_cls_word.setParseAction(TokenTypeParseAction)
# == token value parser ==
code_token = pp.Word(pp.alphanums + '_', exclude_chars="><")
code_token_value = (pp.Word("<EOF>") | pp.White(' ',max=60) | code_token  ).set_name("code_token_value")
token_value_word = pp.Group(
     pp.Word(pp.nums) + pp.Char(":") + pp.Word(pp.nums) 
     + pp.Char("=") + pp.Char("'") + code_token_value + pp.Char("'") 
     + pp.Char(",") + token_type_parser)
token_value_parser = token_value_word.setParseAction(TokenValueParseAction)

def parse_token_type(value:str):
    """
    How debug unexpected behaviour

    * https://stackoverflow.com/questions/7560583/parseexception-expected-end-of-text
    """
    print(">>>>>>>>>>>>")
    print(f"value={value}")
    for toks,start,end in token_type_parser.scanString(value):
        print(toks[0], start, end)

    for toks in token_type_parser.searchString(value):
        print(toks[0])
    print("<<<<<<<<<<<")
    return token_type_parser.parseString(value, parseAll=True)

def parser_token_value(value:str):
    print(">>>>>>>>>>>>")
    print(f"value={value}")
    for toks,start,end in token_value_parser.scanString(value):
        print(toks[0], start, end)

    for toks in token_value_parser.searchString(value):
        print(toks[0])
    print("<<<<<<<<<<<")
    return token_value_parser.parseString(value, parseAll=True)



def parser_token_str(raw_token:str):
    """
    Format the output generated by:

     antlr4-parse vba.g4 module EOF input-filename ../code_samples/vba/sample01.cls -tokens

    A raw token looks like:
    
    [@0,0:4='Const',<'CONST'>,1:0]
    [@1,5:5=' ',<WS>,1:5]
    [@2,6:19='PARMFLAG_CONST',<IDENTIFIER>,1:6]
    [@3,20:20=' ',<WS>,1:20]
    [@4,21:22='As',<'AS'>,1:21]
    [@5,23:23=' ',<WS>,1:23]
    [@6,24:30='Integer',<'INTEGER'>,1:24]
    [@366,932:932=' ',<WS>,41:3]
    [@367,933:935='Sub',<'SUB'>,41:4]
    [@368,936:935='<EOF>',<EOF>,41:7]
    """
    #tokens_list:List[str] =raw_tokens.split("\n")
    # Pyparsing grammar
    lparent = pp.Suppress("[")
    rparent = pp.Suppress("]")
    line_idx_marker = pp.Suppress("@")
    token_idx_word = pp.Word(line_idx_marker+pp.nums)
    token_pos_word = pp.Word(pp.nums+":"+pp.nums)
    


if __name__ == "__main__":
    tokens_types_values = ["<'INTEGER'>","<EOF>","<IDENTIFIER>","<WS>","<'AS'>"]
    print("*** Test tokens types ***")
    for v in tokens_types_values:
        print(f"processing v={v}")
        r = parse_token_type(v)
        print("type=",r[0].value)
    token_values = ["936:935='<EOF>',<EOF>", "6:19='PARMFLAG_CONST',<IDENTIFIER>", "21:22='As',<'AS'>"]
    print("\n*** Test tokens values ***")
    for v in token_values:
        print(f"Processing v={v}")
        print(dict(enumerate(v)))
        r = parser_token_value(v)
        print(r)
        print(r[0].start_byte,"|", r[0].end_byte,"|", r[0].content,"|", r[0].type.value )
        print("-----------------------------")